{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 误差方向传播法的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common.functions import *\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 初始化权重\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        # 生成层\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1']) # 输入层到隐藏层的权重和偏置\n",
    "        self.layers['Relu1'] = Relu() # 隐藏层，Relu激活函数\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2']) # 隐藏层到输出层的权重和偏置\n",
    "        self.lastLayer = SoftmaxWithLoss() # 输出层，SoftmaxWithLoss损失函数\n",
    "\n",
    "    def predict(self, x):\n",
    "        # 前向传播, 计算预测值\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        # 前向传播, 计算损失\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        # 计算梯度, 数值微分\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        return grads\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        # 计算梯度, 反向传播\n",
    "        self.loss(x, t) # 计算损失\n",
    "\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse() # 反转各层顺序，从后往前，反向传播。\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 误差反向传播法的梯度确认\n",
    "\n",
    "目前，已经了解了两种梯度计算方法：基于数值微分法和基于误差反向传播法。后者，即误差反向传播法，是深度学习领域中常用的梯度计算方法，即使存在大量的参数，也可以高效地计算梯度。\n",
    "\n",
    "虽然数值微分用在梯度计算中效率不高，但数值微分法可以用来确认梯度计算结果是否正确。\n",
    "\n",
    "确认数值微分求出的梯度结果和误差反向传播法求出的结果是否一致（严格地讲，是非常相近）的操作称为**梯度确认（gradient check）**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset ...\n",
      "W1: 0.0004942659786859975\n",
      "b1: 0.0029082249047275386\n",
      "W2: 0.005785432008109274\n",
      "b2: 0.28001949666875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "# 读入数据\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normolize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=10, output_size=10)\n",
    "x_batch = x_train[ : 3]\n",
    "t_batch = t_train[ : 3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "# 求各个权重的绝对误差的平均值\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
    "    print(key + \": \" + str(diff))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上代码，使用了训练数据的一部分，确认数值微分求出的梯度与误差反向传播求出的梯度之间的误差。这里误差的计算方法是，求各个权重参数中对应元素的差的绝对值，并求平均值。\n",
    "\n",
    "可以看出，通过数值微分和反向误差传播法求出的梯度差异非常小。从而，可知误差反向传播法求出的梯度是正确的。\n",
    "\n",
    "> 一般来说，数值微分法求出的梯度与误差反向传播法求出的梯度差异在1e-5左右。但是，如果梯度差异大于1e-5，则说明误差反向传播法求出的梯度有误。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用误差方向传播法进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset ...\n",
      "train acc, test acc | 0.15108333333333332, 0.1574\n",
      "train acc, test acc | 0.9047, 0.9082\n",
      "train acc, test acc | 0.9262333333333334, 0.9291\n",
      "train acc, test acc | 0.9372333333333334, 0.9353\n",
      "train acc, test acc | 0.9446833333333333, 0.9426\n",
      "train acc, test acc | 0.9502833333333334, 0.9465\n",
      "train acc, test acc | 0.9559666666666666, 0.953\n",
      "train acc, test acc | 0.9571333333333333, 0.9523\n",
      "train acc, test acc | 0.9625166666666667, 0.9583\n",
      "train acc, test acc | 0.96535, 0.9603\n",
      "train acc, test acc | 0.9676666666666667, 0.9632\n",
      "train acc, test acc | 0.97015, 0.9644\n",
      "train acc, test acc | 0.9712333333333333, 0.9641\n",
      "train acc, test acc | 0.9742, 0.9652\n",
      "train acc, test acc | 0.9744666666666667, 0.9658\n",
      "train acc, test acc | 0.9770666666666666, 0.967\n",
      "train acc, test acc | 0.9767, 0.9663\n",
      "Finished!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from common.two_layers_net import TwoLayerNet\n",
    "\n",
    " # 读入数据\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normolize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000 # 迭代次数\n",
    "train_size = x_train.shape[0] # 训练集大小\n",
    "batch_size = 100 # 每次训练的大小\n",
    "learning_rate = 0.1 # 学习率\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 开始训练\n",
    "iter_per_epoch = max(train_size / batch_size, 1) # 每个epoch需要迭代的次数\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size) # 随机选择一个批次的数据。即，在0-train_size中随机选择batch_size个数据。\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # 通过反向传播计算梯度，loss_b是本轮训练后，更新参数之前的loss值。\n",
    "    grad, loss_b = network.gradient(x_batch, t_batch) # 计算梯度\n",
    "\n",
    "    # 更新参数\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 更新参数后的，本轮训练的loss值。\n",
    "    loss_a = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss_a)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "\n",
    "print(\"Finished!\")\n",
    "\n",
    "# 绘制loss曲线\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(len(train_acc_list)), train_acc_list, label=\"train acc\")\n",
    "plt.plot(np.arange(len(test_acc_list)), test_acc_list, label=\"test acc\", linestyle='--')\n",
    "plt.xlabel(\"epoch count\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim([-0.1, 1.1]) # 设置y轴的取值范围\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
